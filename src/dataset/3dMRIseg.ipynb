{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "3dMRIseg.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9686d7b"
      },
      "source": [
        "import os\n",
        "import math\n",
        "import copy\n",
        "import time\n",
        "import random\n",
        "import pprint\n",
        "import tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "import torch.nn.functional as F\n",
        "from torchvision import utils\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import cv2\n",
        "import nibabel as nib\n",
        "import skimage.transform as skTrans\n",
        "from numpy import logical_and as l_and, logical_not as l_not\n",
        "from scipy.spatial.distance import directed_hausdorff\n",
        "\n",
        "%matplotlib inline"
      ],
      "id": "a9686d7b",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg2fhKLbvuF1",
        "outputId": "999b3737-b959-42dc-f3f8-5429b1962198"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')#, force_remount=True)"
      ],
      "id": "Wg2fhKLbvuF1",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26b8dcb7",
        "outputId": "62d7e580-3713-4a23-aaa7-4c10b77e2b1c"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "id": "26b8dcb7",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de65d8f5"
      },
      "source": [
        "channels = 4\n",
        "resize_shape = (144,144,144)"
      ],
      "id": "de65d8f5",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b22c5449"
      },
      "source": [
        "# Transformations"
      ],
      "id": "b22c5449"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47560ddb"
      },
      "source": [
        "class ScaleToFixed(object):\n",
        "\n",
        "    def __init__(self, new_shape, interpolation=1, channels=4):\n",
        "        self.shape= new_shape\n",
        "        self.interpolation = interpolation\n",
        "        self.channels = channels\n",
        "\n",
        "    def __call__(self, image):\n",
        "        # print('first shape', image.shape)\n",
        "        if image is not None: # (some patients don't have segmentations)\n",
        "            if self.channels == 1:\n",
        "                short_shape = (self.shape[1], self.shape[2], self.shape[3])\n",
        "                image = skTrans.resize(image, short_shape, order=self.interpolation, preserve_range=True)  #\n",
        "                image = image.reshape(self.shape)\n",
        "            else:\n",
        "                image = skTrans.resize(image, self.shape, order=self.interpolation, preserve_range=True)  #\n",
        "\n",
        "        # print('second shape', image.shape)\n",
        "        # print()\n",
        "        return image\n",
        "\n",
        "class RandomFlip(object):\n",
        "    \"\"\"Randomly flips (horizontally as well as vertically) the given PIL.Image with a probability of 0.5\n",
        "    \"\"\"\n",
        "    def __init__(self, prob_flip=0.5):\n",
        "        self.prob_flip= prob_flip\n",
        "    def __call__(self, image):\n",
        "\n",
        "        if random.random() < self.prob_flip:\n",
        "            flip_type = np.random.randint(0, 3) # flip across any 3D axis\n",
        "            image = np.flip(image, flip_type)\n",
        "        return image\n",
        "\n",
        "class ZeroChannel(object):\n",
        "    \"\"\"Randomly sets channel to zero the given PIL.Image with a probability of 0.25\n",
        "    \"\"\"\n",
        "    def __init__(self, prob_zero=0.25, channels=4):\n",
        "        self.prob_zero= prob_zero\n",
        "        self.channels = channels\n",
        "    def __call__(self, image):\n",
        "\n",
        "        if np.random.random() < self.prob_zero:\n",
        "            channel_to_zero = np.random.randint(0, self.channels) # flip across any 3D axis\n",
        "            zeros = np.zeros((image.shape[1], image.shape[2], image.shape[3]))\n",
        "            image[channel_to_zero, :, :, :] = zeros\n",
        "        return image\n",
        "\n",
        "class ZeroSprinkle(object):\n",
        "    def __init__(self, prob_zero=0.25, prob_true=0.5, channels=4):\n",
        "        self.prob_zero=prob_zero\n",
        "        self.prob_true=prob_true\n",
        "        self.channels=channels\n",
        "    def __call__(self, image):\n",
        "\n",
        "        if self.prob_true:\n",
        "            mask = np.random.rand(image.shape[0], image.shape[1], image.shape[2], image.shape[3])\n",
        "            mask[mask < self.prob_zero] = 0\n",
        "            mask[mask > 0] = 1\n",
        "            image = image*mask\n",
        "\n",
        "        return image\n",
        "\n",
        "\n",
        "class MinMaxNormalize(object):\n",
        "    \"\"\"Min-Max normalization\n",
        "    \"\"\"\n",
        "    def __call__(self, image):\n",
        "        def norm(im):\n",
        "            im = im.astype(np.float32)\n",
        "            min_v = np.min(im)\n",
        "            max_v = np.max(im)\n",
        "            im = (im - min_v)/(max_v - min_v)\n",
        "            return im\n",
        "        image = norm(image)\n",
        "        return image\n",
        "\n",
        "class ToTensor(object):\n",
        "    def __init__(self, scale=1):\n",
        "        self.scale = scale\n",
        "\n",
        "    def __call__(self, image):\n",
        "        if image is not None:\n",
        "            image = image.astype(np.float32)\n",
        "            image = image.reshape((image.shape[0], int(image.shape[1]/self.scale), int(image.shape[2]/self.scale), int(image.shape[3]/self.scale)))\n",
        "            image_tensor = torch.from_numpy(image)\n",
        "            return image_tensor\n",
        "        else:\n",
        "            return image\n",
        "\n",
        "\n",
        "class Compose(object):\n",
        "    \"\"\"\n",
        "    Composes several transforms together.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, image):\n",
        "        for i, t in enumerate(self.transforms):\n",
        "            image = t(image)\n",
        "        return image"
      ],
      "id": "47560ddb",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "761d535b"
      },
      "source": [
        "\n",
        "# basic data augmentation\n",
        "prob_voxel_zero = 0 # 0.1\n",
        "prob_channel_zero = 0 # 0.5\n",
        "prob_true = 0 # 0.8\n",
        "randomflip = RandomFlip()\n",
        "\n",
        "# MRI transformations\n",
        "train_transformations = Compose([\n",
        "    MinMaxNormalize(),\n",
        "    ScaleToFixed((channels, resize_shape[0],resize_shape[1],resize_shape[2]),\n",
        "                          interpolation=1,\n",
        "                          channels=channels),\n",
        "    ZeroSprinkle(prob_zero=prob_voxel_zero, prob_true=prob_true),\n",
        "    ZeroChannel(prob_zero=prob_channel_zero),\n",
        "    randomflip,\n",
        "    ToTensor()\n",
        "])\n",
        "\n",
        "# GT segmentation mask transformations\n",
        "\n",
        "seg_transformations = Compose([\n",
        "            ScaleToFixed((1, resize_shape[0],resize_shape[1],resize_shape[2]),\n",
        "                                      interpolation=0,\n",
        "                                      channels=1),\n",
        "            randomflip,\n",
        "            ToTensor(),\n",
        "        ])"
      ],
      "id": "761d535b",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b2edc92"
      },
      "source": [
        "# Dataloader"
      ],
      "id": "2b2edc92"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22e98a7c"
      },
      "source": [
        "def get_bb_3D(img, pad=0):\n",
        "    '''\n",
        "    This function returns a tumor 3D bounding box using a segmentation mask\n",
        "    '''\n",
        "    xs = np.nonzero(np.sum(np.sum(img, axis=1), axis=1))\n",
        "    ys = np.nonzero(np.sum(np.sum(img, axis=0), axis=1))\n",
        "    zs = np.nonzero(np.sum(np.sum(img, axis=0), axis=0))\n",
        "    xmin, xmax = np.min(xs), np.max(xs)\n",
        "    ymin, ymax = np.min(ys), np.max(ys)\n",
        "    zmin, zmax = np.min(zs), np.max(zs)\n",
        "    bbox = (xmin-pad, ymin-pad, zmin-pad, xmax+pad, ymax+pad, zmax+pad)\n",
        "    return bbox\n",
        "\n",
        "def min_max(img):\n",
        "    '''\n",
        "    Min-max normalization\n",
        "    '''\n",
        "    return (img - img.min()) / (img.max() - img.min())\n",
        "\n",
        "def read_mri(mr_path_dict, pad=0):\n",
        "\n",
        "    image_shape = nib.load(mr_path_dict['flair']).get_fdata().shape\n",
        "    bb_seg = get_bb_3D(nib.load(mr_path_dict['flair']).get_fdata())\n",
        "    (xmin, ymin, zmin, xmax, ymax, zmax) = bb_seg\n",
        "\n",
        "    xmin = np.max([0, xmin-pad])\n",
        "    ymin = np.max([0, ymin-pad])\n",
        "    zmin = np.max([0, zmin-pad])\n",
        "\n",
        "    xmax = np.min([image_shape[0]-1, xmax+pad])\n",
        "    ymax = np.min([image_shape[1]-1, ymax+pad])\n",
        "    zmax = np.min([image_shape[2]-1, zmax+pad])\n",
        "\n",
        "\n",
        "    img_dict = {}\n",
        "    for key in ['flair', 't1', 't1ce', 't2', 'seg']:\n",
        "        img = nib.load(mr_path_dict[key])\n",
        "        img_data = img.get_fdata()\n",
        "        img_dict[key] = img_data[xmin:xmax, ymin:ymax, zmin:zmax]\n",
        "\n",
        "    stacked_img = np.stack([min_max(img_dict['flair']), min_max(img_dict['t1']),min_max(img_dict['t1ce']),min_max(img_dict['t2'])], axis=0)\n",
        "    return stacked_img, img_dict['seg']\n"
      ],
      "id": "22e98a7c",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "387e98b8"
      },
      "source": [
        "def plot_(image, seg, predicted=False):\n",
        "    #Overlay with Predicted\n",
        "    img = image[slice, :, :, :].squeeze()\n",
        "    img = utils.make_grid(img)\n",
        "    img = img.detach().cpu().numpy()\n",
        "    \n",
        "    print(img.shape)\n",
        "    \n",
        "    # plot images\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    img_list = [img[i].T for i in range(channels)] # 1 image per channel\n",
        "    plt.imshow(np.hstack(img_list), cmap='Greys_r')\n",
        "    \n",
        "    ## plot segmentation mask ##\n",
        "    seg_img = torch.tensor(pred[slice].squeeze())\n",
        "    if not predicted:\n",
        "        seg_img = torch.tensor(seg_img.numpy()[:, ::-1].copy()) #flip\n",
        "    seg_img = utils.make_grid(seg_img).detach().cpu().numpy()\n",
        "    \n",
        "    print(np.unique(seg_img))\n",
        "\n",
        "    plt.imshow(np.hstack([seg_img[0].T]), cmap='Greys_r', alpha=0.3)\n",
        "    plt.show()\n",
        "    "
      ],
      "id": "387e98b8",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9615fdb0"
      },
      "source": [
        "def calculate_metrics(preds, targets, patient, tta=False):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    preds:\n",
        "        torch tensor of size 1*C*Z*Y*X\n",
        "    targets:\n",
        "        torch tensor of same shape\n",
        "    patient :\n",
        "        The patient ID\n",
        "    tta:\n",
        "        is tta performed for this run\n",
        "    \"\"\"\n",
        "    pp = pprint.PrettyPrinter(indent=4)\n",
        "    assert preds.shape == targets.shape, \"Preds and targets do not have the same size\"\n",
        "\n",
        "    labels = [\"ET\", \"TC\", \"WT\"]\n",
        "\n",
        "    metrics_list = []\n",
        "\n",
        "    for i, label in enumerate(labels):\n",
        "        metrics = dict(\n",
        "            patient_id=patient,\n",
        "            label=label,\n",
        "            tta=tta,\n",
        "        )\n",
        "\n",
        "        if np.sum(targets[i]) == 0:\n",
        "            print(f\"{label} not present for {patient}\")\n",
        "            sens = np.nan\n",
        "            dice = 1 if np.sum(preds[i]) == 0 else 0\n",
        "            tn = np.sum(l_and(l_not(preds[i]), l_not(targets[i])))\n",
        "            fp = np.sum(l_and(preds[i], l_not(targets[i])))\n",
        "            spec = tn / (tn + fp)\n",
        "            haussdorf_dist = np.nan\n",
        "\n",
        "        else:\n",
        "            preds_coords = np.argwhere(preds[i])\n",
        "            targets_coords = np.argwhere(targets[i])\n",
        "            haussdorf_dist = directed_hausdorff(preds_coords, targets_coords)[0]\n",
        "\n",
        "            tp = np.sum(l_and(preds[i], targets[i]))\n",
        "            tn = np.sum(l_and(l_not(preds[i]), l_not(targets[i])))\n",
        "            fp = np.sum(l_and(preds[i], l_not(targets[i])))\n",
        "            fn = np.sum(l_and(l_not(preds[i]), targets[i]))\n",
        "\n",
        "            sens = tp / (tp + fn)\n",
        "            spec = tn / (tn + fp)\n",
        "\n",
        "            dice = 2 * tp / (2 * tp + fp + fn)\n",
        "\n",
        "        metrics[HAUSSDORF] = haussdorf_dist\n",
        "        metrics[DICE] = dice\n",
        "        metrics[SENS] = sens\n",
        "        metrics[SPEC] = spec\n",
        "        pp.pprint(metrics)\n",
        "        metrics_list.append(metrics)\n",
        "\n",
        "    return metrics_list\n",
        "\n",
        "\n",
        "HAUSSDORF = \"haussdorf\"\n",
        "DICE = \"dice\"\n",
        "SENS = \"sens\"\n",
        "SPEC = \"spec\"\n",
        "METRICS = [HAUSSDORF, DICE, SENS, SPEC]\n"
      ],
      "id": "9615fdb0",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0e2443b"
      },
      "source": [
        "class GeneralDataset(Dataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                metadata_df,\n",
        "                root_dir,\n",
        "                transform=None,\n",
        "                seg_transform=None, ###\n",
        "                dataformat=None, # indicates what shape (or content) should be returned (2D or 3D, etc.)\n",
        "                returndims=None, # what size/shape 3D volumes should be returned as.\n",
        "                visualize=False,\n",
        "                modality=None,\n",
        "                pad=2,\n",
        "                device='cpu'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            metadata_df (string): Path to the csv file w/ patient IDs\n",
        "            root_dir (string): Directory for MR images\n",
        "            transform (callable, optional)\n",
        "        \"\"\"\n",
        "        self.device=device\n",
        "        self.metadata_df = metadata_df\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.seg_transform = seg_transform\n",
        "        self.returndims=returndims\n",
        "        self.modality = modality\n",
        "        self.pad = pad\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.metadata_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #print(type(idx), idx)\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        BraTS20ID = self.metadata_df.iloc[idx].BraTS_2020_subject_ID\n",
        "\n",
        "        # make dictonary of paths to MRI volumnes (modalities) and segmenation masks\n",
        "        mr_path_dict = {}\n",
        "        sequence_type = ['seg', 't1', 't1ce', 'flair', 't2']\n",
        "        for seq in sequence_type:\n",
        "            mr_path_dict[seq] = os.path.join(self.root_dir, BraTS20ID, BraTS20ID + '_'+seq+'.nii.gz')\n",
        "\n",
        "        image, seg_image = read_mri(mr_path_dict=mr_path_dict, pad=self.pad)\n",
        "        \n",
        "        if seg_image is not None:\n",
        "            seg_image[seg_image == 4] = 3\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.seg_transform:\n",
        "            seg_image = self.seg_transform(seg_image)\n",
        "        else:\n",
        "            print('no transform')\n",
        "        # print(image.shape)\n",
        "        return (image, seg_image), BraTS20ID"
      ],
      "id": "f0e2443b",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ae38eb1"
      },
      "source": [
        "# Set random seed for reproduciablity\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)\n"
      ],
      "id": "4ae38eb1",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f880651c"
      },
      "source": [
        "\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, epsilon=1e-5):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        # smooth factor\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def forward(self, targets, logits):\n",
        "        batch_size = targets.size(0)\n",
        "        # log_prob = torch.sigmoid(logits)\n",
        "        logits = logits.view(batch_size, -1).type(torch.FloatTensor)\n",
        "        targets = targets.view(batch_size, -1).type(torch.FloatTensor)\n",
        "        intersection = (logits * targets).sum(-1)\n",
        "        dice_score = 2. * intersection / ((logits + targets).sum(-1) + self.epsilon)\n",
        "        # dice_score = 1 - dice_score.sum() / batch_size\n",
        "        return torch.mean(1. - dice_score)"
      ],
      "id": "f880651c",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd4917d4"
      },
      "source": [
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, k_size=3, stride=1, padding=1):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv3d = nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=k_size,\n",
        "                                stride=stride, padding=padding)\n",
        "        self.batch_norm = nn.BatchNorm3d(num_features=out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.batch_norm(self.conv3d(x))\n",
        "        # x = self.conv3d(x)\n",
        "        x = F.elu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, in_channels, init_features, model_depth=4, pool_size=2):\n",
        "        super(EncoderBlock, self).__init__()\n",
        "        self.root_feat_maps = init_features\n",
        "        self.num_conv_blocks = 2\n",
        "        self.module_dict = nn.ModuleDict()\n",
        "        for depth in range(model_depth):\n",
        "            feat_map_channels = 2 ** (depth + 1) * self.root_feat_maps\n",
        "            for i in range(self.num_conv_blocks):\n",
        "                self.conv_block = ConvBlock(in_channels=in_channels, out_channels=feat_map_channels)\n",
        "                self.module_dict[\"conv_{}_{}\".format(depth, i)] = self.conv_block\n",
        "                in_channels, feat_map_channels = feat_map_channels, feat_map_channels * 2\n",
        "            if depth == model_depth - 1:\n",
        "                break\n",
        "            else:\n",
        "                self.pooling = nn.MaxPool3d(kernel_size=pool_size, stride=2, padding=0)\n",
        "                self.module_dict[\"max_pooling_{}\".format(depth)] = self.pooling\n",
        "\n",
        "    def forward(self, x):\n",
        "        down_sampling_features = []\n",
        "        for k, op in self.module_dict.items():\n",
        "            if k.startswith(\"conv\"):\n",
        "                x = op(x)\n",
        "                #print(k, x.shape)\n",
        "                if k.endswith(\"1\"):\n",
        "                    down_sampling_features.append(x)\n",
        "            elif k.startswith(\"max_pooling\"):\n",
        "                x = op(x)\n",
        "                #print(k, x.shape)\n",
        "\n",
        "        return x, down_sampling_features\n",
        "\n",
        "\n",
        "class ConvTranspose(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, k_size=3, stride=2, padding=1, output_padding=1):\n",
        "        super(ConvTranspose, self).__init__()\n",
        "        self.conv3d_transpose = nn.ConvTranspose3d(in_channels=in_channels,\n",
        "                                                   out_channels=out_channels,\n",
        "                                                   kernel_size=k_size,\n",
        "                                                   stride=stride,\n",
        "                                                   padding=padding,\n",
        "                                                   output_padding=output_padding)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv3d_transpose(x)\n",
        "\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, out_channels, init_features, model_depth=4):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        self.num_conv_blocks = 2\n",
        "        self.num_feat_maps = init_features\n",
        "        # user nn.ModuleDict() to store ops\n",
        "        self.module_dict = nn.ModuleDict()\n",
        "\n",
        "        for depth in range(model_depth - 2, -1, -1):\n",
        "            # print(depth)\n",
        "            feat_map_channels = 2 ** (depth + 1) * self.num_feat_maps\n",
        "            # print(feat_map_channels * 4)\n",
        "            self.deconv = ConvTranspose(in_channels=feat_map_channels * 4, out_channels=feat_map_channels * 4)\n",
        "            self.module_dict[\"deconv_{}\".format(depth)] = self.deconv\n",
        "            for i in range(self.num_conv_blocks):\n",
        "                if i == 0:\n",
        "                    self.conv = ConvBlock(in_channels=feat_map_channels * 6, out_channels=feat_map_channels * 2)\n",
        "                    self.module_dict[\"conv_{}_{}\".format(depth, i)] = self.conv\n",
        "                else:\n",
        "                    self.conv = ConvBlock(in_channels=feat_map_channels * 2, out_channels=feat_map_channels * 2)\n",
        "                    self.module_dict[\"conv_{}_{}\".format(depth, i)] = self.conv\n",
        "            if depth == 0:\n",
        "                self.final_conv = ConvBlock(in_channels=feat_map_channels * 2, out_channels=out_channels)\n",
        "                self.module_dict[\"final_conv\"] = self.final_conv\n",
        "\n",
        "    def forward(self, x, down_sampling_features):\n",
        "        \"\"\"\n",
        "        :param x: inputs\n",
        "        :param down_sampling_features: feature maps from encoder path\n",
        "        :return: output\n",
        "        \"\"\"\n",
        "        for k, op in self.module_dict.items():\n",
        "            if k.startswith(\"deconv\"):\n",
        "                x = op(x)\n",
        "                #print(k, x.shape)\n",
        "                x = torch.cat((down_sampling_features[int(k[-1])], x), dim=1)\n",
        "            elif k.startswith(\"conv\"):\n",
        "                x = op(x)\n",
        "                #print(k, x.shape)\n",
        "            else:\n",
        "                x = op(x)\n",
        "                #print(k, x.shape)\n",
        "        return x\n"
      ],
      "id": "fd4917d4",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10186787"
      },
      "source": [
        "class UnetModel(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, init_features, model_depth=4, final_activation=\"sigmoid\"):\n",
        "        super(UnetModel, self).__init__()\n",
        "        self.encoder = EncoderBlock(in_channels=in_channels,\n",
        "                                    init_features=init_features,\n",
        "                                    model_depth=model_depth)\n",
        "        self.decoder = DecoderBlock(out_channels=out_channels,\n",
        "                                    init_features=init_features,\n",
        "                                    model_depth=model_depth)\n",
        "        if final_activation == \"sigmoid\":\n",
        "            self.sigmoid = nn.Sigmoid()\n",
        "        else:\n",
        "            self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, downsampling_features = self.encoder(x)\n",
        "        x = self.decoder(x, downsampling_features)\n",
        "        x = self.sigmoid(x)\n",
        "        # print(\"Final output shape: \", x.shape)\n",
        "        return x\n",
        "\n"
      ],
      "id": "10186787",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de5c0969"
      },
      "source": [
        "def kFoldRun(k_folds, num_epochs, train_batch_size, train_data, validation_data, network, criterion, optim, use_cuda=True):\n",
        "    torch.manual_seed(42)\n",
        "    \n",
        "    if use_cuda:\n",
        "        network = network.cuda()\n",
        "\n",
        "    loss_function = criterion\n",
        "\n",
        "    dataset = ConcatDataset([train_data, validation_data])\n",
        "\n",
        "    # Define the K-fold Cross Validator\n",
        "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
        "\n",
        "    # Start print\n",
        "    print('--------------------------------')\n",
        "\n",
        "    # K-fold Cross Validation model evaluation\n",
        "    for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
        "        # Print\n",
        "        print(f'FOLD {fold}')\n",
        "        print('--------------------------------')\n",
        "    \n",
        "        # Sample elements randomly from a given list of ids, no replacement.\n",
        "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
        "        test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
        "\n",
        "        # Define data loaders for training and testing data in this fold\n",
        "        dataloader_train = DataLoader(dataset, batch_size=train_batch_size,sampler=train_subsampler,num_workers=0)\n",
        "        dataloader_valid = DataLoader(dataset, batch_size=train_batch_size,sampler=test_subsampler, num_workers=0)\n",
        "\n",
        "        # Initialize optimizer\n",
        "        optimizer = torch.optim.Adam(network.parameters(), lr=1e-4)\n",
        "\n",
        "        # Run the training loop for defined number of epochs\n",
        "        for epoch in range(0, num_epochs):\n",
        "            # Print epoch\n",
        "            print(f'Starting epoch {epoch+1}')\n",
        "            start_time = time.time()\n",
        "\n",
        "            # Set current loss value\n",
        "            current_loss = 0.0\n",
        "\n",
        "            # Iterate over the DataLoader for training data\n",
        "            if dataloader_train is None or optimizer is None:\n",
        "                print('None')\n",
        "                break  # NotImplementedError\n",
        "            for i, data in enumerate(tqdm.tqdm(dataloader_train)):\n",
        "                # Get inputs\n",
        "                (inputs, targets), ID = data\n",
        "                #inputs = torch.squeeze(torch.permute(image, (0, 4, 1, 2, 3))) \n",
        "                #label = torch.squeeze(torch.permute(seg_image, (0, 4, 1, 2, 3))) \n",
        "                if use_cuda:\n",
        "                    inputs, targets = inputs.cuda(), targets.cuda() # add this line\n",
        "                # Zero the gradients\n",
        "                optimizer.zero_grad()\n",
        "                # Perform forward pass\n",
        "                outputs = network(inputs)\n",
        "                print(outputs.shape, targets.shape)\n",
        "                # Compute loss\n",
        "                loss = loss_function(outputs, targets.squeeze(1).long())\n",
        "                print('Loss:', loss.item())\n",
        "                # Perform backward pass\n",
        "                loss.backward()\n",
        "\n",
        "                # Perform optimization\n",
        "                optimizer.step()\n",
        "\n",
        "                # Print statistics\n",
        "                current_loss += loss.item()\n",
        "                if i % 500 == 499:\n",
        "                    print('Loss after mini-batch %5d: %.3f' %\n",
        "                          (i + 1, current_loss / 500))\n",
        "                    current_loss = 0.0\n",
        "            end_time = time.time()\n",
        "            print(f\"Epoch Time: {end_time - start_time}\")\n",
        "    # Process is complete.\n",
        "    print('Training process has finished. Saving trained model.')\n",
        "    \n",
        "    # Saving the model\n",
        "    save_path = f'./model-fold-{fold}.pth'\n",
        "    torch.save(network.state_dict(), 'drive/MyDrive/Colab Notebooks/')\n",
        "\n",
        "    # Print about testing\n",
        "    print('Starting testing')\n",
        "    # Evaluationfor this fold\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        # Iterate over the test data and generate predictions\n",
        "        for i, data in enumerate(dataloader_valid, 0):\n",
        "            # Get inputs\n",
        "            inputs, targets = data\n",
        "            # inputs = torch.squeeze(torch.permute(image, (0, 4, 1, 2, 3))) # \n",
        "            # label = torch.squeeze(torch.permute(seg_image, (0, 4, 1, 2, 3))) #, 0) \n",
        "            if use_cuda:\n",
        "                inputs, targets = inputs.cuda(), targets.cuda() # add this line\n",
        "\n",
        "            # Generate outputs\n",
        "            outputs = network(inputs)\n",
        "\n",
        "            # Set total and correct\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "        # Print accuracy\n",
        "        print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
        "        print('--------------------------------')\n",
        "        results[fold] = 100.0 * (correct / total)\n",
        "    \n",
        "    # Print fold results\n",
        "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
        "    print('--------------------------------')\n",
        "    sum = 0.0\n",
        "    for key, value in results.items():\n",
        "        print(f'Fold {key}: {value} %')\n",
        "        sum += value\n",
        "    print(f'Average: {sum/len(results.items())} %')\n",
        "\n",
        "    return results"
      ],
      "id": "de5c0969",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IapCD4ZDzxnm"
      },
      "source": [
        "def train_epochs(network, use_cuda, dataloader_train, loss_function, optimizer, num_epochs):\n",
        "    ################\n",
        "    history = {'train_loss': [], 'train_acc':[]}\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Starting Train epoch: {epoch+1}')\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "\n",
        "        for i, data in enumerate(tqdm.tqdm(dataloader_train)):\n",
        "            (inputs, targets), ID = data\n",
        "            if use_cuda:\n",
        "                inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            outputs = network(inputs)\n",
        "            loss = loss_function(outputs, targets.squeeze(1).long())\n",
        "            print('Train Loss:', loss.item())\n",
        "\n",
        "            train_loss += loss.item() * outputs.size(0) #multiplying by batchsize\n",
        "\n",
        "            _, predictions = torch.max(outputs.data, 1) #change\n",
        "            train_correct += (predictions == targets).sum().item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Print statistics\n",
        "           \n",
        "        history['train_loss'].append(train_loss / len(dataloader_train.sampler))\n",
        "        history['train_acc'].append(train_correct / len(dataloader_train.sampler))\n",
        "\n",
        "        print(f\"Epoch loss: {history['train_loss'][-1]}\")\n",
        "\n",
        "    return history['train_loss'][-1], history['train_acc'][-1], history\n",
        "\n",
        "\n",
        "def valid_epoch(network, use_cuda, dataloader_valid, loss_function):\n",
        "    valid_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        # Iterate over the test data and generate predictions\n",
        "        for i, data in enumerate(dataloader_valid, 0):\n",
        "            inputs, targets = data\n",
        "            if use_cuda:\n",
        "                inputs, targets = inputs.cuda(), targets.cuda() \n",
        "            outputs = network(inputs)\n",
        "            loss = loss_function(outputs, targets.squeeze(1).long())\n",
        "            print('Valid Loss:', loss.item())\n",
        "            #################\n",
        "            valid_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "            #################\n",
        "        # Print accuracy\n",
        "        valid_loss /= len(dataloader_valid.sampler) \n",
        "        valid_acc = 100.0 * (correct / len(dataloader_valid.sampler))\n",
        "        print(f\" Fold Accuracy: {valid_acc}\")\n",
        "\n",
        "        if valid < best:\n",
        "            best = validation_loss\n",
        "            model_dict = model.state_dict()\n",
        "            save_checkpoint(\n",
        "                dict(\n",
        "                    epoch=epoch, arch=args.arch,\n",
        "                    state_dict=model_dict,\n",
        "                    optimizer=optimizer.state_dict(),\n",
        "                    scheduler=scheduler.state_dict(),\n",
        "                ),\n",
        "                save_folder=args.save_folder, )\n",
        "\n",
        "    return valid_loss, valid_acc\n",
        "\n",
        "\n"
      ],
      "id": "IapCD4ZDzxnm",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHcAuoOmBAyX"
      },
      "source": [
        "\n",
        "def save_model(model, optimizer, fold, epoch, loss):\n",
        "    # Saving the model\n",
        "    save_path = f'model-fold-{fold}.pth'\n",
        "\n",
        "    checkpoint = {'epoch': epoch,\n",
        "                  'model_state_dict': model.state_dict(),\n",
        "                  'optimizer_state_dict': optimizer.state_dict(),\n",
        "                  'loss': loss,\n",
        "                  }\n",
        "    torch.save(checkpoint, save_path)\n"
      ],
      "id": "rHcAuoOmBAyX",
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rpe78jm4TOa"
      },
      "source": [
        "def train_test_epochs(model, loss_function, optimizer, dataloader_train, dataloader_valid, fold, num_epochs, use_cuda):\n",
        "    train_history = {'train_loss': [], 'train_acc':[]}\n",
        "    valid_history = {'valid_loss': [], 'valid_acc':[]}\n",
        "    best = math.inf\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Starting Train epoch: {epoch+1}')\n",
        "\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "\n",
        "        for i, data in enumerate(tqdm.tqdm(dataloader_train)):\n",
        "            (inputs, targets), ID = data\n",
        "            if use_cuda:\n",
        "                inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_function(outputs, targets.squeeze(1).long())\n",
        "            print('Train Loss:', loss.item())\n",
        "\n",
        "            train_loss += loss.item() * outputs.size(0) #multiplying by batchsize\n",
        "\n",
        "            _, predictions = torch.max(outputs.data, 1) #change\n",
        "            train_correct += (predictions == targets).sum().item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "           \n",
        "        train_history['train_loss'].append(train_loss / len(dataloader_train.sampler))\n",
        "        train_history['train_acc'].append(train_correct / len(dataloader_train.sampler))\n",
        "\n",
        "        print(f\"Train Epoch loss: {train_history['train_loss'][-1]}\")\n",
        "\n",
        "        valid_loss = 0.0\n",
        "        correct, total = 0, 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Iterate over the test data and generate predictions\n",
        "            for i, data in enumerate(tqdm.tqdm(dataloader_valid)):\n",
        "                (inputs, targets), ID = data\n",
        "                if use_cuda:\n",
        "                    inputs, targets = inputs.cuda(), targets.cuda() \n",
        "                outputs = model(inputs)\n",
        "                loss = loss_function(outputs, targets.squeeze(1).long())\n",
        "                print('Valid Loss:', loss.item())\n",
        "                #################\n",
        "                valid_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                correct += (predicted == targets).sum().item()\n",
        "                #################\n",
        "            # Print accuracy\n",
        "            valid_loss /= len(dataloader_valid.sampler) \n",
        "            valid_acc = 100.0 * (correct / len(dataloader_valid.sampler))\n",
        "            print(f\" Fold Accuracy: {valid_acc}\")\n",
        "\n",
        "        valid_history['valid_loss'].append(valid_loss)\n",
        "        valid_history['valid_acc'].append(valid_acc)\n",
        "\n",
        "        print(f\"Val Epoch loss: {valid_history['valid_loss'][-1]}\")\n",
        "\n",
        "        # saving best model for this fold\n",
        "        if valid_loss < best:\n",
        "            best = valid_loss\n",
        "            save_model(model, optimizer, fold, epoch, loss)\n",
        "\n",
        "    return train_history['train_loss'][-1], train_history['train_acc'][-1], train_history, \n",
        "    valid_history['valid_loss'][-1], valid_history['valid_acc'][-1], valid_history"
      ],
      "id": "9rpe78jm4TOa",
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHLhJATvnKYH",
        "outputId": "6817a17e-fdb0-4054-bf9e-8d09aefd3471"
      },
      "source": [
        "\n",
        "kfold = KFold(n_splits=2, shuffle=True)\n",
        "dataset = ConcatDataset([transformed_dataset_train, transformed_dataset_valid])\n",
        "\n",
        "train_ids, test_ids =  next(iter(kfold.split(dataset)))\n",
        "print(test_ids)\n",
        "print('--------------------------------')\n",
        "# Sample elements randomly from a given list of ids, no replacement.\n",
        "train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
        "test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
        "\n",
        "# Define data loaders for training and testing data in this fold\n",
        "dataloader_train = DataLoader(dataset, batch_size=2, sampler=train_subsampler, num_workers=0)\n",
        "dataloader_valid = DataLoader(dataset, batch_size=2, sampler=test_subsampler, num_workers=0)\n",
        "\n",
        "\n"
      ],
      "id": "DHLhJATvnKYH",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1  2  5  8 10 11 14 16 18 19 20 23 25 26 27 28 33 35 36 39]\n",
            "--------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkrzErySn2Pl",
        "outputId": "6de4ad90-0b2f-4748-9014-5286f511c933"
      },
      "source": [
        "with torch.no_grad():\n",
        "    # Iterate over the test data and generate predictions\n",
        "    (h, k), ID = next(iter(dataloader_train))\n",
        "    print(type(h), type(k))\n",
        "      "
      ],
      "id": "JkrzErySn2Pl",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yFCVWV6n28o"
      },
      "source": [
        ""
      ],
      "id": "7yFCVWV6n28o",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrPBRDAvoN5q"
      },
      "source": [
        ""
      ],
      "id": "KrPBRDAvoN5q",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-CPyh9L15GF"
      },
      "source": [
        "def kFoldRunAll(model, criterion, optim, train_data, validation_data, k_folds, num_epochs, train_batch_size, use_cuda):\n",
        "    torch.manual_seed(42)\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "\n",
        "    loss_function = criterion\n",
        "    dataset = ConcatDataset([train_data, validation_data])\n",
        "    # Define the K-fold Cross Validator\n",
        "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
        "\n",
        "    fold_train_history = {}\n",
        "    fold_valid_history = {}\n",
        "    fold_train_and_valid_acc = {}\n",
        "    fold_train_and_valid_loss = {}\n",
        "\n",
        "    print('--------------------------------')\n",
        "    # K-fold Cross Validation model evaluation\n",
        "    for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
        "        print(f'FOLD {fold}')\n",
        "        print('--------------------------------')\n",
        "        # Sample elements randomly from a given list of ids, no replacement.\n",
        "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
        "        test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
        "\n",
        "        # Define data loaders for training and testing data in this fold\n",
        "        dataloader_train = DataLoader(dataset, batch_size=train_batch_size, sampler=train_subsampler, num_workers=0)\n",
        "        dataloader_valid = DataLoader(dataset, batch_size=train_batch_size, sampler=test_subsampler, num_workers=0)\n",
        "\n",
        "        # Initialize optimizer\n",
        "        optimizer = optim\n",
        "\n",
        "        # Run the training, testing and saving loop for defined number of epochs\n",
        "        start_time = time.time()\n",
        "\n",
        "        t_loss, t_acc, t_history, v_loss, v_acc, v_history = train_test_epochs(model, loss_function, optimizer,\n",
        "                                                                               dataloader_train, dataloader_valid,\n",
        "                                                                               fold, num_epochs, use_cuda)\n",
        "\n",
        "        end_time = time.time()\n",
        "        print(f\"Epoch Time: {end_time - start_time}\")\n",
        "\n",
        "        #Saving loss results \n",
        "        fold_train_and_valid_loss[str(fold)] = [t_loss, v_loss]\n",
        "        fold_train_and_valid_acc[str(fold)] = [t_acc, v_acc]\n",
        "        fold_train_history[str(fold)] = t_history\n",
        "        fold_valid_history[str(fold)] = v_history\n",
        "\n",
        "        # Print accuracy\n",
        "        print(f'Accuracy for fold {fold}: {v_acc}')\n",
        "        print(f'Loss for fold {fold}: {v_loss}')\n",
        "        print('--------------------------------')  \n",
        "\n",
        "    return fold_train_history, fold_valid_history, fold_train_and_valid_loss, fold_train_and_valid_acc\n",
        "  \n"
      ],
      "id": "k-CPyh9L15GF",
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAOcgA9icb6W"
      },
      "source": [
        "\n",
        "\n",
        "def plot_metric(train, valid, metric_name):\n",
        "    # Plot losses\n",
        "    plt.figure(figsize=(10,8))\n",
        "    plt.semilogy(train, label='Train')\n",
        "    plt.semilogy(valid, label='Valid')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel(metric_name)\n",
        "    plt.legend()\n",
        "    plt.title(f'Model {metric_name} Plot')\n",
        "    plt.show()\n",
        "    plt.clf()\n",
        "\n",
        "def plot_result(num_epochs, fold_train_history, fold_valid_history):\n",
        "    final_fold = {'train_loss':[],'valid_loss':[],'train_acc':[],'valid_acc':[]}\n",
        "\n",
        "    for epoch in range(num_epochs):                                      \n",
        "        final_fold['train_loss'].append(np.mean([fold_train_history[str(fold)]['train_loss'][epoch] for fold in range(kfolds)]))\n",
        "        final_fold['valid_loss'].append(np.mean([fold_valid_history[str(fold)]['valid_loss'][epoch]for fold in range(kfolds)]))\n",
        "        final_fold['train_acc'].append(np.mean([fold_train_history[str(fold)]['train_acc'][epoch]for fold in range(kfolds)]))\n",
        "        final_fold['valid_acc'].append(np.mean([fold_valid_history[str(fold)]['valid_acc'][epoch]for fold in range(kfolds)]))\n",
        "\n",
        "    plot_metric(final_fold['train_loss'], final_fold['valid_loss'], 'Loss')\n",
        "    plot_metric(final_fold['train_acc'], final_fold['valid_acc'], 'Accuracy')\n"
      ],
      "id": "HAOcgA9icb6W",
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a92e81a8"
      },
      "source": [
        "\n",
        "def train_main(train, valid, in_channels, out_channels, init_features, learning_rate, k_folds, no_epochs, train_batch_size):\n",
        "    \"\"\"\n",
        "    Train module\n",
        "    :param data_folder: data folder\n",
        "    :param in_channels: the input channel of input images\n",
        "    :param out_channels: the final output channel\n",
        "    :param learning_rate: set learning rate for training\n",
        "    :param no_epochs: number of epochs to train model\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    model = UnetModel(in_channels=in_channels, out_channels=out_channels,\n",
        "                      init_features=init_features)\n",
        "    optim = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "    #criterion = DiceLoss()\n",
        "    criterion = CrossEntropyLoss()\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    t_history, v_history, tv_loss, tv_acc = kFoldRunAll(model, criterion, optim,\n",
        "                                                        train, valid,\n",
        "                                                        k_folds, no_epochs,\n",
        "                                                        train_batch_size,\n",
        "                                                        use_cuda)\n",
        "    \n",
        "    plot_result(no_epochs, t_history, v_history)"
      ],
      "id": "a92e81a8",
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10df01db"
      },
      "source": [
        "# Data"
      ],
      "id": "10df01db"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "131cb88d"
      },
      "source": [
        "\n",
        "image_dir = 'drive/MyDrive/Colab Notebooks/MICCAI_BraTS2020_TrainingData/'\n",
        "naming = pd.read_csv(f'drive/MyDrive/Colab Notebooks/MICCAI_BraTS2020_TrainingData/name_mapping.csv')\n",
        "\n",
        "data_df = pd.DataFrame(naming['BraTS_2020_subject_ID'])\n",
        "n_p = 20 # n_patients_to_train_with\n",
        "train_df = data_df[:n_p]\n",
        "valid_df = data_df[n_p:n_p*2]"
      ],
      "id": "131cb88d",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "775a8888"
      },
      "source": [
        "transformed_dataset_train = GeneralDataset(metadata_df=train_df, \n",
        "                                           root_dir=image_dir,\n",
        "                                           transform=train_transformations,\n",
        "                                           seg_transform=seg_transformations,\n",
        "                                           returndims=resize_shape)\n",
        "\n",
        "transformed_dataset_valid = GeneralDataset(metadata_df=valid_df, \n",
        "                                           root_dir=image_dir,\n",
        "                                           transform=train_transformations,\n",
        "                                           seg_transform=seg_transformations,\n",
        "                                           returndims=resize_shape)"
      ],
      "id": "775a8888",
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "107d0ad6"
      },
      "source": [
        "channels = 4\n",
        "resize_shape = (144,144,144)"
      ],
      "id": "107d0ad6",
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c37708e6",
        "outputId": "69ab4a65-c4c3-481e-fcb9-07ac0a81028d"
      },
      "source": [
        "train_main(transformed_dataset_train, transformed_dataset_valid, in_channels=4,\n",
        "           out_channels=4, init_features=4, learning_rate=1e-4, k_folds=2,\n",
        "           no_epochs=3, train_batch_size=2)"
      ],
      "id": "c37708e6",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "FOLD 0\n",
            "--------------------------------\n",
            "Starting Train epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|         | 1/10 [00:11<01:47, 11.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.3912442922592163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|        | 2/10 [00:23<01:33, 11.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.3883370161056519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|       | 3/10 [00:35<01:21, 11.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.3818974494934082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|      | 4/10 [00:46<01:09, 11.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.3788005113601685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|     | 5/10 [00:58<00:58, 11.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.3725768327713013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|    | 6/10 [01:09<00:46, 11.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.3752583265304565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|   | 7/10 [01:21<00:34, 11.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.370758056640625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 8/10 [01:32<00:23, 11.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.3752810955047607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%| | 9/10 [01:44<00:11, 11.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.3709559440612793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10/10 [01:55<00:00, 11.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.3721274137496948\n",
            "Train Epoch loss: 1.3777236938476562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|         | 1/10 [00:11<01:42, 11.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.3647671937942505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|        | 2/10 [00:23<01:32, 11.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.368791103363037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|       | 3/10 [00:34<01:20, 11.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.361297845840454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|      | 4/10 [00:45<01:08, 11.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.3694045543670654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|     | 5/10 [00:57<00:57, 11.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.3709602355957031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|    | 6/10 [01:09<00:46, 11.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.3612005710601807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|   | 7/10 [01:21<00:35, 11.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.3604273796081543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 8/10 [01:32<00:23, 11.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.372279405593872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%| | 9/10 [01:44<00:11, 11.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.3640974760055542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10/10 [01:56<00:00, 11.62s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.3690590858459473\n",
            " Fold Accuracy: 282018200.0\n",
            "Val Epoch loss: 1.3662284851074218\n",
            "Starting Train epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|         | 1/10 [00:11<01:45, 11.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.3652409315109253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|        | 2/10 [00:23<01:34, 11.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.367870807647705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|       | 3/10 [00:35<01:23, 11.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.3649587631225586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|      | 4/10 [00:47<01:11, 11.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.3621537685394287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|     | 5/10 [00:58<00:58, 11.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.355141520500183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|    | 6/10 [01:10<00:46, 11.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.36250638961792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|   | 7/10 [01:22<00:35, 11.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.3549476861953735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 8/10 [01:34<00:23, 11.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.3590283393859863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%| | 9/10 [01:45<00:11, 11.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.3567270040512085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10/10 [01:57<00:00, 11.73s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.3590023517608643\n",
            "Train Epoch loss: 1.3607577562332154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|         | 1/10 [00:11<01:44, 11.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.3537724018096924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|        | 2/10 [00:23<01:33, 11.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.3566924333572388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|       | 3/10 [00:34<01:21, 11.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.3565257787704468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|      | 4/10 [00:46<01:09, 11.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.3544209003448486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|     | 5/10 [00:57<00:57, 11.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.3520203828811646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|    | 6/10 [01:09<00:46, 11.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.358034610748291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|   | 7/10 [01:21<00:34, 11.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.3539916276931763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 8/10 [01:32<00:22, 11.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.3550121784210205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%| | 9/10 [01:43<00:11, 11.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.3458833694458008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10/10 [01:55<00:00, 11.57s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.3518940210342407\n",
            " Fold Accuracy: 292705225.0\n",
            "Val Epoch loss: 1.3538247704505921\n",
            "Starting Train epoch: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|         | 1/10 [00:11<01:46, 11.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.3526220321655273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|        | 2/10 [00:23<01:33, 11.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.3503224849700928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|       | 3/10 [00:35<01:21, 11.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.3529770374298096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|      | 4/10 [00:46<01:10, 11.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.3478285074234009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|     | 5/10 [00:58<00:58, 11.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.345108985900879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|    | 6/10 [01:09<00:46, 11.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.345410943031311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|   | 7/10 [01:21<00:35, 11.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.3491337299346924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 8/10 [01:33<00:23, 11.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.3509191274642944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%| | 9/10 [01:44<00:11, 11.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.357401967048645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10/10 [01:56<00:00, 11.65s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.3469284772872925\n",
            "Train Epoch loss: 1.3498653292655944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|         | 1/10 [00:11<01:45, 11.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.3445147275924683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|        | 2/10 [00:23<01:33, 11.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.3524267673492432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|       | 3/10 [00:34<01:21, 11.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.344847321510315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|      | 4/10 [00:46<01:09, 11.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.346929907798767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|     | 5/10 [00:58<00:57, 11.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.3496114015579224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|    | 6/10 [01:09<00:46, 11.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.3422654867172241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|   | 7/10 [01:21<00:34, 11.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.3443429470062256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 8/10 [01:32<00:23, 11.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.3480671644210815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%| | 9/10 [01:44<00:11, 11.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.3449431657791138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10/10 [01:55<00:00, 11.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Loss: 1.34572434425354\n",
            " Fold Accuracy: 330987855.0\n",
            "Val Epoch loss: 1.34636732339859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-f47b39a8fdde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train_main(transformed_dataset_train, transformed_dataset_valid, in_channels=4,\n\u001b[1;32m      2\u001b[0m            \u001b[0mout_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m            no_epochs=3, train_batch_size=2)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-74-a776da5a3369>\u001b[0m in \u001b[0;36mtrain_main\u001b[0;34m(train, valid, in_channels, out_channels, init_features, learning_rate, k_folds, no_epochs, train_batch_size)\u001b[0m\n\u001b[1;32m     20\u001b[0m                                                         \u001b[0mk_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                                                         \u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                                                         use_cuda)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mplot_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-2fed392e0954>\u001b[0m in \u001b[0;36mkFoldRunAll\u001b[0;34m(model, criterion, optim, train_data, validation_data, k_folds, num_epochs, train_batch_size, use_cuda)\u001b[0m\n\u001b[1;32m     35\u001b[0m         t_loss, t_acc, t_history, v_loss, v_acc, v_history = train_test_epochs(model, loss_function, optimizer,\n\u001b[1;32m     36\u001b[0m                                                                                \u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                                                                                fold, num_epochs, use_cuda)\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 6, got 3)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "535877c1"
      },
      "source": [
        ""
      ],
      "id": "535877c1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08145b0f"
      },
      "source": [
        ""
      ],
      "id": "08145b0f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5c466f6"
      },
      "source": [
        ""
      ],
      "id": "c5c466f6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc92b9b8"
      },
      "source": [
        "model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
        "                        in_channels=4, out_channels=4, init_features=4,\n",
        "                        pretrained=False)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)"
      ],
      "id": "bc92b9b8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc4e677c"
      },
      "source": [
        "### Training loop here\n",
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    model = model.cuda()\n",
        "\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    losses = []\n",
        "    if dataloader_train is None or optimizer is None:\n",
        "        break  # NotImplementedError\n",
        "    for data in tqdm.tqdm(dataloader_train):\n",
        "        (image, seg_image), bratsID = data\n",
        "        \n",
        "        p_image = torch.squeeze(torch.permute(image, (0, 4, 1, 2, 3))) \n",
        "        p_seg_image = torch.squeeze(torch.permute(seg_image, (0, 4, 1, 2, 3))) \n",
        "\n",
        "        if use_cuda:\n",
        "            p_image, p_seg_image = p_image.cuda(), p_seg_image.cuda() \n",
        "        pred = model(p_image.float())\n",
        "        loss = criterion(pred, p_seg_image.long())\n",
        "        \n",
        "        print(loss.item())\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    print(\"Epoch:\", epoch, \"Mean Loss:\", np.mean(losses))\n",
        "\n",
        "###End"
      ],
      "id": "cc4e677c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbc4fcda"
      },
      "source": [
        "torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, 'drive/MyDrive/Colab Notebooks/resumable_third_10_50e_mriseg.pt')"
      ],
      "id": "bbc4fcda",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "a9c6c212"
      },
      "source": [
        "model = torch.load('second_100_mriseg.pt', map_location=torch.device('cpu'))\n",
        "model.eval()"
      ],
      "id": "a9c6c212",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1150012e"
      },
      "source": [
        "\n",
        "pred = model(p_image.float())\n",
        "#pred = model(p_image[:, 0, :, :].unsqueeze(1).float()) # only for 0(flair) modality model"
      ],
      "id": "1150012e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28ee5e1b"
      },
      "source": [
        "slice = 72"
      ],
      "id": "28ee5e1b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ef01764"
      },
      "source": [
        "plt.imshow(cv2.resize(pred[slice, 2, :, :].detach().cpu().numpy(), (160, 160), interpolation = cv2.INTER_NEAREST))\n"
      ],
      "id": "4ef01764",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb7003f4"
      },
      "source": [
        "torch.argmax(pred[0, 1:, 0, 8])"
      ],
      "id": "eb7003f4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b1322db"
      },
      "source": [
        "pred_seg = torch.sigmoid(pred)\n",
        "segs = pred_seg.permute(1, 0, 2, 3).detach().cpu().numpy() > 0.52   #4, 144, 144, 144 now i.e c, d, h, w"
      ],
      "id": "3b1322db",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7acbb4af"
      },
      "source": [
        "pred[0, :, 0, 8]"
      ],
      "id": "7acbb4af",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fecea6a"
      },
      "source": [
        "pred_seg[0, :, 0, 8]"
      ],
      "id": "6fecea6a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9e03305"
      },
      "source": [
        "#On predictions- get Regions\n",
        "et = segs[1]\n",
        "net = np.logical_and(segs[2], np.logical_not(et))\n",
        "ed = np.logical_and(segs[3], np.logical_not(segs[2]))\n",
        "\n",
        "labelmap = np.zeros(segs[1].shape)\n",
        "labelmap[et] = 3\n",
        "labelmap[net] = 1\n",
        "labelmap[ed] = 2\n",
        "\n",
        "print(f\"voxel values : {np.unique(labelmap)}\")"
      ],
      "id": "b9e03305",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f7dc6d9"
      },
      "source": [
        "#visualize any 2d slice\n",
        "\n",
        "plt.imshow(labelmap[slice])\n",
        "print(f\"pixel values: {np.unique(labelmap[slice])}\")"
      ],
      "id": "9f7dc6d9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5526d9d0"
      },
      "source": [
        ""
      ],
      "id": "5526d9d0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2d85fbc"
      },
      "source": [
        "ref_seg = p_seg_image.squeeze()\n",
        "refmap_et, refmap_tc, refmap_wt = [np.zeros_like(ref_seg) for i in range(3)]\n",
        "refmap_et = ref_seg == 3\n",
        "refmap_tc = np.logical_or(refmap_et, ref_seg == 1)\n",
        "refmap_wt = np.logical_or(refmap_tc, ref_seg == 2)\n",
        "refmap = np.stack([refmap_et, refmap_tc, refmap_wt])"
      ],
      "id": "f2d85fbc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04fcb1a6"
      },
      "source": [
        "patient_metric_list = calculate_metrics(segs[1:], refmap, 'test')"
      ],
      "id": "04fcb1a6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "686b8da9"
      },
      "source": [
        "#Overlay with Ground seg\n",
        "\n",
        "\n",
        "\n",
        "img = p_image[slice, :, :, :].squeeze()\n",
        "img = utils.make_grid(img)\n",
        "img = img.detach().cpu().numpy()\n",
        "print(img.shape)\n",
        "# plot images\n",
        "plt.figure(figsize=(10, 8))\n",
        "img_list = [img[i].T for i in range(channels)] # 1 image per channel\n",
        "plt.imshow(np.hstack(img_list), cmap='Greys_r')\n",
        "\n",
        "\n",
        "## plot segmentation mask ##\n",
        "seg_img = p_seg_image[slice, :, :, :].squeeze()\n",
        "print(seg_img.shape)\n",
        "seg_img = torch.tensor(seg_img.numpy()[:, ::-1].copy()) #flip\n",
        "seg_img = utils.make_grid(seg_img).detach().cpu().numpy()\n",
        "\n",
        "print(np.unique(p_seg_image))\n",
        "#seg_img = seg_img > 1\n",
        "plt.imshow(np.hstack([seg_img[0].T]), cmap='Greys_r', alpha=0.5)\n",
        "plt.show()"
      ],
      "id": "686b8da9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce2e7b9c"
      },
      "source": [
        "#Overlay with Predicted\n",
        "img = p_image[slice, :, :, :].squeeze()\n",
        "img = utils.make_grid(img)\n",
        "img = img.detach().cpu().numpy()\n",
        "print(img.shape)\n",
        "# plot images\n",
        "plt.figure(figsize=(10, 8))\n",
        "img_list = [img[i].T for i in range(channels)] # 1 image per channel\n",
        "plt.imshow(np.hstack(img_list), cmap='Greys_r')\n",
        "## plot segmentation mask ##\n",
        "seg_img = torch.tensor(labelmap[slice, :, :].squeeze())\n",
        "seg_img = utils.make_grid(seg_img).detach().cpu().numpy()\n",
        "print(np.unique(seg_img))\n",
        "\n",
        "#plt.figure(figsize=(4, 4))\n",
        "plt.imshow(np.hstack([seg_img[0].T]), cmap='Greys_r', alpha=0.3)\n",
        "plt.show()"
      ],
      "id": "ce2e7b9c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f8644da"
      },
      "source": [
        ""
      ],
      "id": "7f8644da",
      "execution_count": null,
      "outputs": []
    }
  ]
}